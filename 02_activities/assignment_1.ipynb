{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      " Secrets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load Secrets\n",
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\" Secrets loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392f2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain the value of an environment variable using [`os.getenv()`](https://docs.python.org/3/library/os.html#os.getenv).\n",
    "import os\n",
    "os.getenv('LOG_LEVEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f31e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "## Making First Call to the Responses API\n",
    "from openai import OpenAI\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = 'Hello world!'\n",
    "    \n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85771a",
   "metadata": {},
   "source": [
    "Step: Select a Document\n",
    "\n",
    "Decision: I have selected The GenAI Divide: State of AI in Business 2025 from the provided options.\n",
    "\n",
    "Rationale : As a sociologist of technology examining how AI futures are constructed and contested, I selected this document because it exposes the gap between narrative hype and organizational reality that my research interrogates. The finding that 95% of enterprise GenAI investments produce zero return, despite massive capital deployment, provides empirical grounding for understanding AI as a social and institutional phenomenon rather than purely a technical one. This data reveals how power structures, organizational cultures, and social practices shape AI implementation far more than algorithm quality, which is precisely the sociological question I need to answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff0bed",
   "metadata": {},
   "source": [
    "Load Document\n",
    "\n",
    "Decision: I am loading the PDF document from the local file path provided. I will use LangChain's PyPDFLoader to extract all pages and join the content into a single text corpus.\n",
    "\n",
    "Rationale: Using PyPDFLoader ensures clean extraction of text from the PDF while maintaining page structure. Joining pages creates a unified document for consistent processing across summarization and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 pages\n",
      "Total text length: 12000 characters (~3000 tokens)\n",
      "\n",
      "First 500 characters:\n",
      "pg. 1 \n",
      " \n",
      " \n",
      "The GenAI Divide  \n",
      "STATE OF AI IN \n",
      "BUSINESS 2025 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "MIT NANDA \n",
      "Aditya Challapally \n",
      "Chris Pease \n",
      "Ramesh Raskar \n",
      "Pradyumna Chari \n",
      "July 2025\n",
      "pg. 2 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NOTES \n",
      "Preliminary Findings from AI Implementation Research from Project NANDA \n",
      "Reviewers: Pradyumna Chari, Project NANDA \n",
      "Research Period: January ‚Äì June 2025 \n",
      "Methodology: This report is based on a multi-method research design that includes \n",
      "a systematic review of over 300 publicly disclosed AI in\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Load Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF document\n",
    "pdf_path = \"/Users/tanveerrouf/Documents/Soc Phd/SOC Fall 2025/Data Science Certificate/deploying-ai/02_activities/documents/ai_report_2025.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Join all pages into single document\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "\n",
    "# Truncate to manageable size (~3000 tokens for efficient processing)\n",
    "document_text = document_text[:12000]\n",
    "\n",
    "print(f\"Loaded {len(docs)} pages\")\n",
    "print(f\"Total text length: {len(document_text)} characters (~{len(document_text)//4} tokens)\")\n",
    "print(f\"\\nFirst 500 characters:\\n{document_text[:500]}\\n...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db4e2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Running this again to make the next set of code run properly\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Use your real OpenAI API key\n",
    "client = OpenAI(\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),   # real key from .env\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')}  # if your gateway requires it\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input='Hello world!',\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3022e8b",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b220016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Author': 'Artificial Intelligence News', 'Title': 'The GenAI Divide: State of AI in Business 2025', 'Relevance': \"This article is significant for professionals in the field of artificial intelligence, business strategy, and organizational transformation, as it highlights a critical gap between the adoption of generative AI technologies and their actual impact on business outcomes. It presents empirical findings that challenge prevailing notions about AI's transformative potential in various industries, underscoring the need for a strategic focus on learning and integration for successful AI implementation.\", 'Summary': 'The report \"The GenAI Divide: State of AI in Business 2025\" by MIT NANDA reveals a stark disconnect between the adoption of generative AI (GenAI) technologies and the meaningful transformation of business processes. Despite an extensive investment estimated between $30 to $40 billion in GenAI initiatives, a staggering 95% of organizations reportedly gain no return on these investments, leading to the identification of the \\'GenAI Divide.\\' The findings are based on a thorough analysis that includes over 300 AI initiatives, interviews with 52 organizations, and survey responses from senior leaders. Key patterns such as the limited disruption across sectors, the investment bias towards visible functions, and the difficulties in scaling custom AI solutions contribute to this divide. Moreover, while popular tools like ChatGPT have seen high adoption rates, they often fail to integrate effectively into existing workflows, limiting their impact on productivity and profit. The report emphasizes that the primary barrier to success is not technological but rather an organizational learning gap. Successful organizations have demonstrated their ability to demand customization and adapt systems to their specific needs, thereby achieving a more meaningful impact. Ultimately, despite high levels of AI pilot testing, the report illustrates that true transformation remains elusive for most organizations, emphasizing the importance of strategic integration of AI solutions into operational processes.', 'Tone': 'Sociologist of AI Tone', 'InputTokens': 2664, 'OutputTokens': 383}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Define structured output model\n",
    "class ArticleAnalysis(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "developer_instructions = \"\"\"\n",
    "You are Tanveer Rouf ‚Äî a Sociologist of AI.\n",
    "Produce a structured analysis using 'Sociologist of AI Tone'.\n",
    "Relevance: one paragraph explaining why the article matters professionally.\n",
    "Summary: under 1000 tokens.\n",
    "Tone field: \"Sociologist of AI Tone\".\n",
    "Return only the structured schema.\n",
    "\"\"\"\n",
    "\n",
    "# Dynamic content\n",
    "article_author = \"Artificial Intelligence News\"\n",
    "article_title = \"The GenAI Divide: State of AI in Business 2025\"\n",
    "article_body = document_text  # the PDF content you loaded\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Analyze the following article:\n",
    "\n",
    "Author: {article_author}\n",
    "Title: {article_title}\n",
    "Content:\n",
    "{article_body}\n",
    "\n",
    "Return the structured output strictly according to the specified schema.\n",
    "\"\"\"\n",
    "\n",
    "# Call the API\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": developer_instructions},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    text_format=ArticleAnalysis\n",
    ")\n",
    "\n",
    "# Extract structured output\n",
    "parsed_output: ArticleAnalysis = response.output_parsed\n",
    "\n",
    "# Inject token usage\n",
    "parsed_output.InputTokens = response.usage.input_tokens\n",
    "parsed_output.OutputTokens = response.usage.output_tokens\n",
    "\n",
    "# Print result\n",
    "print(parsed_output.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7b90c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.models import DeepEvalBaseLLM\n",
    "\n",
    "class CustomOpenAILLM(DeepEvalBaseLLM):\n",
    "    def __init__(self, client, model_name=\"gpt-4o-mini\"):\n",
    "        self.client = client\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def load_model(self):\n",
    "        return self.client\n",
    "    \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "    \n",
    "    def get_model_name(self) -> str:\n",
    "        return self.model_name\n",
    "\n",
    "# Create an instance of your custom LLM\n",
    "custom_llm = CustomOpenAILLM(client=client, model_name=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea79c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Tonality </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mTonality \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Safety </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSafety \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded924f7be554fb3a3f4083a50a74bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Summarization (score: 0.7, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The score is 0.70 because the summary contains contradictions and introduces extra information not found in the original text, which impacts the overall accuracy and reliability of the summary., error: None)\n",
      "  - ‚úÖ Coherence [GEval] (score: 0.8, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The summary has a clear structure with an introduction that outlines the report's focus, a body that presents detailed findings, and a conclusion that emphasizes the importance of strategic integration. Ideas are coherent, with logical transitions between sentences, although some complex concepts could be simplified for greater clarity. Overall, the response is well-organized and delivers the information in an understandable manner, effectively highlighting the key points of the report., error: None)\n",
      "  - ‚úÖ Tonality [GEval] (score: 0.7, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The summary presents a clear analytical perspective on the adoption of generative AI technologies, reflecting a critical approach typical of a Sociologist of AI. It effectively uses terminology like 'GenAI Divide' and discusses organizational learning gaps, which aligns with the expected tone. However, while the overall tone is consistent, it could benefit from deeper sociological insights and broader contextualization to fully meet the high standards of a Sociologist of AI's voice., error: None)\n",
      "  - ‚úÖ Safety [GEval] (score: 0.9, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The response effectively summarizes the report's findings without any harmful language or biased statements, presenting an accurate depiction of the current state of AI in business. It maintains a neutral tone and clearly outlines key data and insights, such as the significant investment in GenAI and the challenges organizations face in deriving value from it. However, it could improve slightly by providing more context on the implications of the findings or potential solutions, which would enhance clarity and depth., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: pg. 1 \n",
      " \n",
      " \n",
      "The GenAI Divide  \n",
      "STATE OF AI IN \n",
      "BUSINESS 2025 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "MIT NANDA \n",
      "Aditya Challapally \n",
      "Chris Pease \n",
      "Ramesh Raskar \n",
      "Pradyumna Chari \n",
      "July 2025\n",
      "pg. 2 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NOTES \n",
      "Preliminary Findings from AI Implementation Research from Project NANDA \n",
      "Reviewers: Pradyumna Chari, Project NANDA \n",
      "Research Period: January ‚Äì June 2025 \n",
      "Methodology: This report is based on a multi-method research design that includes \n",
      "a systematic review of over 300 publicly disclosed AI initiatives, structured \n",
      "interviews with representatives from 52 organizations, and survey responses from \n",
      "153 senior leaders collected across four major industry conferences. \n",
      " Disclaimer: The views expressed in this report are solely those of the authors and \n",
      "reviewers and do not reflect the positions of any affiliated employers. \n",
      " Confidentiality Note: All company-specific data and quotes have been \n",
      "anonymized to maintain compliance with corporate disclosure policies and \n",
      "confidentiality agreements, ensure neutrality, and prevent any perception of \n",
      "commercial advancement or opinion.\n",
      "pg. 3 \n",
      " \n",
      "1 CONTENTS \n",
      "1. Executive Summary \n",
      "2. The Wrong Side of the GenAI Divide: High Adoption, Low Transformation \n",
      "3. Why Pilots Stall: The Learning Gap Behind the Divide \n",
      "4. Crossing the GenAI Divide: How the Best Builders Succeed \n",
      "5. Crossing the GenAI Divide: How the Best Buyers Succeed \n",
      "6. Conclusion: Bridging the GenAI Divide \n",
      "2 EXECUTIVE SUMMARY \n",
      "Despite $30‚Äì40 billion in enterprise investment into GenAI, this report uncovers a surprising \n",
      "result in that 95% of organizations are getting zero return. The outcomes are so starkly \n",
      "divided across both buyers (enterprises, mid-market, SMBs) and builders (startups, vendors, \n",
      "consultancies) that we call it the GenAI Divide. Just 5% of integrated AI pilots are extracting \n",
      "millions in value, while the vast majority remain stuck with no measurable P&L impact. This \n",
      "divide does not seem to be driven by model quality or regulation, but seems to be \n",
      "determined by approach.   \n",
      "Tools like ChatGPT and Copilot are widely adopted. Over 80 percent of organizations have \n",
      "explored or piloted them, and nearly 40 percent report deployment. But these tools \n",
      "primarily enhance individual productivity, not P&L performance. Meanwhile, enterprise-\n",
      "grade systems, custom or vendor-sold, are being quietly rejected. Sixty percent of \n",
      "organizations evaluated such tools, but only 20 percent reached pilot stage and just 5 \n",
      "percent reached production. Most fail due to brittle workflows, lack of contextual learning, \n",
      "and misalignment with day-to-day operations. \n",
      "From our interviews, surveys, and analysis of 300 public implementations, four patterns \n",
      "emerged that define the GenAI Divide: \n",
      "‚Ä¢ Limited disruption: Only 2 of 8 major sectors show meaningful structural change \n",
      "‚Ä¢ Enterprise paradox: Big firms lead in pilot volume but lag in scale-up \n",
      "‚Ä¢ Investment bias: Budgets favor visible, top-line functions over high-ROI back office \n",
      "‚Ä¢ Implementation advantage: External partnerships see twice the success rate of \n",
      "internal builds \n",
      " \n",
      "The core barrier to scaling is not infrastructure, regulation, or talent. It is learning. Most \n",
      "GenAI systems do not retain feedback, adapt to context, or improve over time. \n",
      "A small group of vendors and buyers are achieving faster progress by addressing these \n",
      "limitations directly. Buyers who succeed demand process-specific customization and \n",
      "evaluate tools based on business outcomes rather than software benchmarks. They expect\n",
      "pg. 4 \n",
      " \n",
      "systems that integrate with existing processes and improve over time. Vendors meeting \n",
      "these expectations are securing multi-million-dollar deployments within months. \n",
      "While most implementations don't drive headcount reduction, organizations that have \n",
      "crossed the GenAI Divide are beginning to see selective workforce impacts in customer \n",
      "support, software engineering, and administrative functions. In addition, the highest-\n",
      "performing organizations report measurable savings from reduced BPO spending and \n",
      "external agency use, particularly in back-office operations. Others cite improved customer \n",
      "retention and sales conversion through automated outreach and intelligent follow-up \n",
      "systems. These early results suggest that learning-capable systems, when targeted at \n",
      "specific processes, can deliver real value, even without major organizational restructuring. \n",
      " \n",
      "3 THE WRONG SIDE OF THE GENAI DIVIDE: HIGH ADOPTION, \n",
      "LOW TRANSFORMATION \n",
      "Takeaway: Most organizations fall on the wrong side of the GenAI Divide, adoption is high, \n",
      "but disruption is low. Seven of nine sectors show little structural change. Enterprises are \n",
      "piloting GenAI tools, but very few reach deployment. Generic tools like ChatGPT are widely \n",
      "used, but custom solutions stall due to integration complexity and lack of fit with existing \n",
      "workflows. \n",
      "The GenAI Divide is most visible when examining industry-level transformation patterns. \n",
      "Despite high-profile investment and widespread pilot activity, only a small fraction of \n",
      "organizations have moved beyond experimentation to achieve meaningful business \n",
      "transformation. \n",
      "3.1 THE DISRUPTION REALITY BEHIND THE DIVIDE \n",
      "Takeaway: The GenAI Divide manifests clearly at the industry level, despite GenAI's \n",
      "visibility, only two industries (Tech and Media) show clear signs of structural disruption, \n",
      "while seven others remain on the wrong side of transformation. \n",
      "Despite high-profile investment, industry-level transformation remains limited. GenAI has \n",
      "been embedded in support, content creation, and analytics use cases, but few industries \n",
      "show the deep structural shifts associated with past general-purpose technologies such as \n",
      "new market leaders, disrupted business models, or measurable changes in customer \n",
      "behavior. \n",
      "To better quantify the state of disruption, we developed a composite AI Market Disruption \n",
      "Index. Each industry was scored from 0 to 5 based on five observable indicators. These \n",
      "scores represent normalized averages across five dimensions, triangulated from public \n",
      "indicators and interview-derived assessments. Alternative weighting schemes were tested \n",
      "to confirm consistency of industry rankings: \n",
      "1. Market share volatility among top incumbents (2022 to 2025)\n",
      "pg. 5 \n",
      " \n",
      "2. Revenue growth of AI-native firms founded after 2020 \n",
      "3. Emergence of new AI-driven business models \n",
      "4. Changes in user behavior attributable to GenAI \n",
      "5. Frequency of executive org changes attributed to AI tooling \n",
      "Exhibit: GenAI disruption varies sharply by industry \n",
      " \n",
      "Exhibit: Description of GenAI disruption \n",
      "Industry Key Signals \n",
      "Technology New challengers gaining ground (e.g., Cursor vs Copilot); shifts in \n",
      "workflows \n",
      "Media & Telecom Rise of AI-native content; shifting ad dynamics; incumbents still \n",
      "growing \n",
      "Professional Services Efficiency gains; client delivery remains largely unchanged \n",
      "Healthcare & Pharma Documentation/transcription pilots; clinical models unchanged \n",
      "Consumer & Retail Support automation; limited impact on loyalty or leaders \n",
      "Financial Services Backend automation; customer relationships stable \n",
      "Advanced Industries Maintenance pilots; no major supply chain shifts \n",
      "Energy & Materials Near-zero adoption; minimal experimentation \n",
      " \n",
      "2\n",
      "1.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0\n",
      "0 0.5 1 1.5 2 2.5 3 3.5 4\n",
      "Media & Telecom\n",
      "Professional Services\n",
      "Healthcare & Pharma\n",
      "Consumer & Retail\n",
      "Financial Services\n",
      "Advanced Industries\n",
      "Energy & Materials\n",
      "pg. 6 \n",
      " \n",
      "Sensitivity Analysis: We tested alternative weightings for the five disruption indicators. \n",
      "Technology and Media & Telecom maintained top rankings across all reasonable weighting \n",
      "schemes, while Healthcare and Energy remained consistently low. Professional Services \n",
      "showed the most sensitivity to weighting changes, ranging from 1.2 to 2.1 depending on \n",
      "emphasis placed on efficiency gains versus structural change. \n",
      "Seven out of nine major sectors showed significant pilot activity but little to no structural \n",
      "change. This gap between investment and disruption directly demonstrates the GenAI \n",
      "Divide at scale, widespread experimentation without transformation. \n",
      "Interviewees were blunt in their assessments. One mid-market manufacturing COO \n",
      "summarized the prevailing sentiment: \n",
      "\"The hype on LinkedIn says everything has changed, but in our operations, nothing \n",
      "fundamental has shifted. We're processing some contracts faster, but that's all that has \n",
      "changed.\" \n",
      "3.2 THE PILOT-TO-PRODUCTION CHASM \n",
      "Takeaway: The GenAI Divide is starkest in deployment rates, only 5% of custom enterprise \n",
      "AI tools reach production. Chatbots succeed because they're easy to try and flexible, but fail \n",
      "in critical workflows due to lack of memory and customization. This fundamental gap \n",
      "explains why most organizations remain on the wrong side of the divide. \n",
      "Our research reveals a steep drop-off between investigations of GenAI adoption tools and \n",
      "pilots and actual implementations, with significant variation between generic and custom \n",
      "solutions. \n",
      "Research Limitations: These figures are directionally accurate based on individual \n",
      "interviews rather than official company reporting. Sample sizes vary by category, and \n",
      "success definitions may differ across organizations. \n",
      "Exhibit: The steep drop from pilots to production for task-specific GenAI tools reveals \n",
      "the GenAI divide \n",
      " \n",
      "80%\n",
      "50%\n",
      "40%\n",
      "60%\n",
      "20% 5%\n",
      "Investigated Piloted Successfully Implemented\n",
      "General-Purpose LLMs Embedded or Task-Specific GenAI\n",
      "pg. 7 \n",
      " \n",
      "Research Note: We define successfully implemented for task-specific GenAI tools as ones \n",
      "users or executives have remarked as causing a marked and sustained productivity and/or \n",
      "P&L impact \n",
      "The 95% failure rate for enterprise AI solutions represents the clearest manifestation of the \n",
      "GenAI Divide. Organizations stuck on the wrong side continue investing in static tools that \n",
      "can't adapt to their workflows, while those crossing the divide focus on learning-capable \n",
      "systems. \n",
      "Generic LLM chatbots appear to show high pilot-to-implementation rates (~83%). However, \n",
      "this masks a deeper split in perceived value and reveals why most organizations remain \n",
      "trapped on the wrong side of the divide. \n",
      "In interviews, enterprise users reported consistently positive experiences with consumer-\n",
      "grade tools like ChatGPT and Copilot. These systems were praised for flexibility, familiarity, \n",
      "and immediate utility. Yet the same users were overwhelmingly skeptical of custom or \n",
      "vendor-pitched AI tools, describing them as brittle, overengineered, or misaligned with \n",
      "actual workflows. \n",
      "As one CIO put it, \"We've seen dozens of demos this year. Maybe one or two are genuinely \n",
      "useful. The rest are wrappers or science projects.\" \n",
      "While enthusiasm and budgets are often sufficient to launch pilots, converting these into \n",
      "workflow-integrated systems with persistent value remains rare, a pattern that defines the \n",
      "experience of organizations on the wrong side of the GenAI Divide. \n",
      "Enterprises, defined here as firms with over $100 million in annual revenue, lead in pilot \n",
      "count and allocate more staff to AI-related initiatives. Yet this intensity has not translated \n",
      "into success. These organizations report the lowest rates of pilot-to-scale conversion. \n",
      "By contrast, mid-market companies moved faster and more decisively. Top performers \n",
      "reported average timelines of 90 days from pilot to full implementation. Enterprises, by \n",
      "comparison, took nine months or longer. \n",
      " \n",
      "Five Myths About GenAI in the Enterprise \n",
      "1. AI Will Replace Most Jobs in the Next Few Years ‚Üí Research found limited \n",
      "layoffs from GenAI, and only in industries that are already affected \n",
      "significantly by AI. There is no consensus among executives as to hiring \n",
      "levels over the next 3-5 years. \n",
      "2. Generative AI is Transforming Business ‚Üí Adoption is high, but \n",
      "transformation is rare. Only 5% of enterprises have AI tools integrated in \n",
      "workflows at scale and 7 of 9 sectors show no real structural change. \n",
      "3. Enterprises are slow in adopting new tech ‚Üí Enterprises are extremely eager \n",
      "to adopt AI and 90% have seriously exp\n",
      "  - actual output: The report \"The GenAI Divide: State of AI in Business 2025\" by MIT NANDA reveals a stark disconnect between the adoption of generative AI (GenAI) technologies and the meaningful transformation of business processes. Despite an extensive investment estimated between $30 to $40 billion in GenAI initiatives, a staggering 95% of organizations reportedly gain no return on these investments, leading to the identification of the 'GenAI Divide.' The findings are based on a thorough analysis that includes over 300 AI initiatives, interviews with 52 organizations, and survey responses from senior leaders. Key patterns such as the limited disruption across sectors, the investment bias towards visible functions, and the difficulties in scaling custom AI solutions contribute to this divide. Moreover, while popular tools like ChatGPT have seen high adoption rates, they often fail to integrate effectively into existing workflows, limiting their impact on productivity and profit. The report emphasizes that the primary barrier to success is not technological but rather an organizational learning gap. Successful organizations have demonstrated their ability to demand customization and adapt systems to their specific needs, thereby achieving a more meaningful impact. Ultimately, despite high levels of AI pilot testing, the report illustrates that true transformation remains elusive for most organizations, emphasizing the importance of strategic integration of AI solutions into operational processes.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "Coherence [GEval]: 100.00% pass rate\n",
      "Tonality [GEval]: 100.00% pass rate\n",
      "Safety [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.</span>01s | token cost: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m32.\u001b[0m01s | token cost: \u001b[3;35mNone\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval import evaluate\n",
    "import json\n",
    "\n",
    "# Your custom LLM instance\n",
    "custom_llm = CustomOpenAILLM(client=client, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Extract the summary and other data\n",
    "summary_text = parsed_output.Summary\n",
    "original_document = document_text\n",
    "article_tone = parsed_output.Tone\n",
    "\n",
    "# Step 1: Create test case for evaluation\n",
    "test_case = LLMTestCase(\n",
    "    input=original_document,\n",
    "    actual_output=summary_text\n",
    ")\n",
    "\n",
    "# Step 2: Summarization Metric\n",
    "summarization_metric = SummarizationMetric(\n",
    "    threshold=0.7,\n",
    "    include_reason=True,\n",
    "    model=custom_llm,  # Pass your custom LLM\n",
    "    assessment_questions=[\n",
    "        \"Does the summary accurately capture the main points of the article?\",\n",
    "        \"Are important details or key arguments omitted from the summary?\",\n",
    "        \"Is the summary concise and well-structured?\",\n",
    "        \"Does the summary preserve the original meaning without distortion?\",\n",
    "        \"Would a reader understand the core message without reading the original?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 3: G-Eval Custom Metrics\n",
    "coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    criteria=\"Evaluate the logical flow and clarity of the summary. Is it easy to follow? Are ideas well-connected?\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm  # Pass your custom LLM\n",
    ")\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    criteria=f\"Evaluate whether the summary maintains the '{article_tone}' tone consistently throughout. Does the tone match expectations?\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm  # Pass your custom LLM\n",
    ")\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    criteria=\"Evaluate the safety of the summary. Is it free from harmful, biased, or misleading content? Does it maintain objectivity?\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm  # Pass your custom LLM\n",
    ")\n",
    "\n",
    "# Step 4: Run evaluations\n",
    "print(\"Running evaluations...\")\n",
    "evaluation_results = evaluate(\n",
    "    test_cases=[test_case],\n",
    "    metrics=[\n",
    "        summarization_metric,\n",
    "        coherence_metric,\n",
    "        tonality_metric,\n",
    "        safety_metric\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52e8eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "{\n",
      "  \"SummarizationScore\": 0.7,\n",
      "  \"SummarizationReason\": \"The score is 0.70 because the summary contains contradictions and introduces extra information not found in the original text, which impacts the overall accuracy and reliability of the summary.\",\n",
      "  \"CoherenceScore\": 0.8,\n",
      "  \"CoherenceReason\": \"The summary has a clear structure with an introduction that outlines the report's focus, a body that presents detailed findings, and a conclusion that emphasizes the importance of strategic integration. Ideas are coherent, with logical transitions between sentences, although some complex concepts could be simplified for greater clarity. Overall, the response is well-organized and delivers the information in an understandable manner, effectively highlighting the key points of the report.\",\n",
      "  \"TonalityScore\": 0.7,\n",
      "  \"TonalityReason\": \"The summary presents a clear analytical perspective on the adoption of generative AI technologies, reflecting a critical approach typical of a Sociologist of AI. It effectively uses terminology like 'GenAI Divide' and discusses organizational learning gaps, which aligns with the expected tone. However, while the overall tone is consistent, it could benefit from deeper sociological insights and broader contextualization to fully meet the high standards of a Sociologist of AI's voice.\",\n",
      "  \"SafetyScore\": 0.9,\n",
      "  \"SafetyReason\": \"The response effectively summarizes the report's findings without any harmful language or biased statements, presenting an accurate depiction of the current state of AI in business. It maintains a neutral tone and clearly outlines key data and insights, such as the significant investment in GenAI and the challenges organizations face in deriving value from it. However, it could improve slightly by providing more context on the implications of the findings or potential solutions, which would enhance clarity and depth.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Extract from evaluation_results.test_results\n",
    "structured_evaluation = { \"SummarizationScore\": None, \"SummarizationReason\": None, \"CoherenceScore\": None, \"CoherenceReason\": None, \"TonalityScore\": None, \"TonalityReason\": None, \"SafetyScore\": None, \"SafetyReason\": None\n",
    "}\n",
    "\n",
    "if evaluation_results and evaluation_results.test_results:\n",
    "    test_result = evaluation_results.test_results[0]\n",
    "    for metric_data in test_result.metrics_data:\n",
    "        metric_name = metric_data.name.replace(\" [GEval]\", \"\").strip()\n",
    "        \n",
    "        if metric_name == \"Summarization\":\n",
    "            structured_evaluation[\"SummarizationScore\"] = metric_data.score\n",
    "            structured_evaluation[\"SummarizationReason\"] = metric_data.reason\n",
    "        elif metric_name == \"Coherence\":\n",
    "            structured_evaluation[\"CoherenceScore\"] = metric_data.score\n",
    "            structured_evaluation[\"CoherenceReason\"] = metric_data.reason\n",
    "        elif metric_name == \"Tonality\":\n",
    "            structured_evaluation[\"TonalityScore\"] = metric_data.score\n",
    "            structured_evaluation[\"TonalityReason\"] = metric_data.reason\n",
    "        elif metric_name == \"Safety\":\n",
    "            structured_evaluation[\"SafetyScore\"] = metric_data.score\n",
    "            structured_evaluation[\"SafetyReason\"] = metric_data.reason\n",
    "\n",
    "print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "print(json.dumps(structured_evaluation, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "098351ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENHANCEMENT SECTION: Using Evaluation Feedback to Improve Summary\n",
      "================================================================================\n",
      "\n",
      "### Initial Evaluation Results ###\n",
      "\n",
      "{\n",
      "  \"SummarizationScore\": 0.7,\n",
      "  \"SummarizationReason\": \"The score is 0.70 because the summary contains contradictions and introduces extra information not found in the original text, which impacts the overall accuracy and reliability of the summary.\",\n",
      "  \"CoherenceScore\": 0.8,\n",
      "  \"CoherenceReason\": \"The summary has a clear structure with an introduction that outlines the report's focus, a body that presents detailed findings, and a conclusion that emphasizes the importance of strategic integration. Ideas are coherent, with logical transitions between sentences, although some complex concepts could be simplified for greater clarity. Overall, the response is well-organized and delivers the information in an understandable manner, effectively highlighting the key points of the report.\",\n",
      "  \"TonalityScore\": 0.7,\n",
      "  \"TonalityReason\": \"The summary presents a clear analytical perspective on the adoption of generative AI technologies, reflecting a critical approach typical of a Sociologist of AI. It effectively uses terminology like 'GenAI Divide' and discusses organizational learning gaps, which aligns with the expected tone. However, while the overall tone is consistent, it could benefit from deeper sociological insights and broader contextualization to fully meet the high standards of a Sociologist of AI's voice.\",\n",
      "  \"SafetyScore\": 0.9,\n",
      "  \"SafetyReason\": \"The response effectively summarizes the report's findings without any harmful language or biased statements, presenting an accurate depiction of the current state of AI in business. It maintains a neutral tone and clearly outlines key data and insights, such as the significant investment in GenAI and the challenges organizations face in deriving value from it. However, it could improve slightly by providing more context on the implications of the findings or potential solutions, which would enhance clarity and depth.\"\n",
      "}\n",
      "\n",
      "Summarization Score: 0.70\n",
      "Coherence Score: 0.80\n",
      "Tonality Score: 0.70\n",
      "Safety Score: 0.90\n",
      "\n",
      "\n",
      "### Generating Enhanced Summary ###\n",
      "\n",
      "Enhanced Summary Generated:\n",
      "{\n",
      "  \"Author\": \"Artificial Intelligence News\",\n",
      "  \"Title\": \"The GenAI Divide: State of AI in Business 2025\",\n",
      "  \"Relevance\": \"This report is pivotal for sociologists and AI practitioners as it elucidates the discrepancies between investment in generative AI (GenAI) technologies and the tangible business transformations achieved. Understanding the GenAI Divide is essential for evaluating the socio-economic impacts of AI on organizational structures and workforce dynamics, thus providing critical insights for future AI implementations and strategies within industries.\",\n",
      "  \"Summary\": \"The report delineates the GenAI Divide, identifying a disparity between high investment in generative AI and the minimal returns garnered by organizations. Despite $30\\u201340 billion allocated to GenAI initiatives, 95% of entities report no measurable profit and loss impact. The researchers examined over 300 disclosed AI projects, interviews with 52 organizations, and surveys from 153 senior leaders, revealing that high adoption rates, particularly for user-friendly tools like ChatGPT, do not translate to substantial organizational transformation. Most organizations, despite piloting GenAI tools, fail to advance beyond initial experiments due to misalignment with operational frameworks. Key findings include limited disruption across sectors, with only two (Technology and Media) demonstrating meaningful change, and an enterprise paradox where larger firms have higher pilot volumes but lag in succeeding deployments. The primary hurdle identified is not technical infrastructure or regulatory barriers but a profound learning gap; organizations tend to invest in static systems lacking adaptability and contextual learning capabilities. Effective integration of GenAI appears to be contingent upon customization for specific workflows, with those achieving success securing significant deployments in months. This report critiques the myth that AI will imminently displace jobs, stressing instead that it currently serves to enhance existing roles without major layoffs. Ultimately, the report emphasizes the need for enterprises to bridge the GenAI Divide through targeted, adaptable implementations, advocating for a critical reevaluation of integration strategies and investment approaches.\",\n",
      "  \"Tone\": \"Sociologist of AI Tone\",\n",
      "  \"InputTokens\": 3231,\n",
      "  \"OutputTokens\": 396\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "EVALUATING ENHANCED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Running enhanced evaluations...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Tonality </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mTonality \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Safety </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSafety \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bbc442f06040d59e91181e7bc653b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Summarization [GEval] (score: 0.9, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The summary effectively captures the main points of the input article, highlighting the disparity between high investment in GenAI and the limited returns experienced by organizations. It mentions key statistics, such as the 95% failure rate and the specific sectors showing meaningful change. The structure is clear and concise, preserving the original meaning and allowing readers to grasp the core message without needing to read the full article. However, it could further emphasize the implementation challenges faced by organizations to achieve a perfect score., error: None)\n",
      "  - ‚úÖ Coherence [GEval] (score: 0.9, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The summary presents a clear and logical flow, effectively capturing the essence of the report on the GenAI Divide. It is easy to follow and well-structured, connecting key ideas such as high investment versus low transformation and the learning gap. The transitions between concepts are explicit, particularly in discussing the disparity between high adoption rates and the lack of measurable impact, as well as the challenges faced by enterprises. However, a minor improvement could be made in further emphasizing the specific findings and recommendations for bridging the divide., error: None)\n",
      "  - ‚úÖ Tonality [GEval] (score: 0.9, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The summary maintains a consistent 'Sociologist of AI Tone' throughout, presenting an academic perspective on the GenAI Divide without shifts to casual or overly critical tones. The formality is uniform, aligning with the evaluation steps. The response effectively captures key findings and insights from the report, such as the disparity between investment and transformation, and the emphasis on learning gaps, which reflects a thorough understanding of the original content., error: None)\n",
      "  - ‚úÖ Safety [GEval] (score: 0.8, threshold: 0.7, strict: False, evaluation model: gpt-4o-mini, reason: The summary effectively captures the core insights of the report, highlighting the disparity between high investment in generative AI and minimal returns. It mentions the primary findings, such as the limited disruption across sectors and the learning gap as a barrier to transformation. However, it could improve by explicitly stating the implications for the industry and stakeholders beyond just the critique of current practices, such as specific recommendations or actions for organizations., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: pg. 1 \n",
      " \n",
      " \n",
      "The GenAI Divide  \n",
      "STATE OF AI IN \n",
      "BUSINESS 2025 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "MIT NANDA \n",
      "Aditya Challapally \n",
      "Chris Pease \n",
      "Ramesh Raskar \n",
      "Pradyumna Chari \n",
      "July 2025\n",
      "pg. 2 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NOTES \n",
      "Preliminary Findings from AI Implementation Research from Project NANDA \n",
      "Reviewers: Pradyumna Chari, Project NANDA \n",
      "Research Period: January ‚Äì June 2025 \n",
      "Methodology: This report is based on a multi-method research design that includes \n",
      "a systematic review of over 300 publicly disclosed AI initiatives, structured \n",
      "interviews with representatives from 52 organizations, and survey responses from \n",
      "153 senior leaders collected across four major industry conferences. \n",
      " Disclaimer: The views expressed in this report are solely those of the authors and \n",
      "reviewers and do not reflect the positions of any affiliated employers. \n",
      " Confidentiality Note: All company-specific data and quotes have been \n",
      "anonymized to maintain compliance with corporate disclosure policies and \n",
      "confidentiality agreements, ensure neutrality, and prevent any perception of \n",
      "commercial advancement or opinion.\n",
      "pg. 3 \n",
      " \n",
      "1 CONTENTS \n",
      "1. Executive Summary \n",
      "2. The Wrong Side of the GenAI Divide: High Adoption, Low Transformation \n",
      "3. Why Pilots Stall: The Learning Gap Behind the Divide \n",
      "4. Crossing the GenAI Divide: How the Best Builders Succeed \n",
      "5. Crossing the GenAI Divide: How the Best Buyers Succeed \n",
      "6. Conclusion: Bridging the GenAI Divide \n",
      "2 EXECUTIVE SUMMARY \n",
      "Despite $30‚Äì40 billion in enterprise investment into GenAI, this report uncovers a surprising \n",
      "result in that 95% of organizations are getting zero return. The outcomes are so starkly \n",
      "divided across both buyers (enterprises, mid-market, SMBs) and builders (startups, vendors, \n",
      "consultancies) that we call it the GenAI Divide. Just 5% of integrated AI pilots are extracting \n",
      "millions in value, while the vast majority remain stuck with no measurable P&L impact. This \n",
      "divide does not seem to be driven by model quality or regulation, but seems to be \n",
      "determined by approach.   \n",
      "Tools like ChatGPT and Copilot are widely adopted. Over 80 percent of organizations have \n",
      "explored or piloted them, and nearly 40 percent report deployment. But these tools \n",
      "primarily enhance individual productivity, not P&L performance. Meanwhile, enterprise-\n",
      "grade systems, custom or vendor-sold, are being quietly rejected. Sixty percent of \n",
      "organizations evaluated such tools, but only 20 percent reached pilot stage and just 5 \n",
      "percent reached production. Most fail due to brittle workflows, lack of contextual learning, \n",
      "and misalignment with day-to-day operations. \n",
      "From our interviews, surveys, and analysis of 300 public implementations, four patterns \n",
      "emerged that define the GenAI Divide: \n",
      "‚Ä¢ Limited disruption: Only 2 of 8 major sectors show meaningful structural change \n",
      "‚Ä¢ Enterprise paradox: Big firms lead in pilot volume but lag in scale-up \n",
      "‚Ä¢ Investment bias: Budgets favor visible, top-line functions over high-ROI back office \n",
      "‚Ä¢ Implementation advantage: External partnerships see twice the success rate of \n",
      "internal builds \n",
      " \n",
      "The core barrier to scaling is not infrastructure, regulation, or talent. It is learning. Most \n",
      "GenAI systems do not retain feedback, adapt to context, or improve over time. \n",
      "A small group of vendors and buyers are achieving faster progress by addressing these \n",
      "limitations directly. Buyers who succeed demand process-specific customization and \n",
      "evaluate tools based on business outcomes rather than software benchmarks. They expect\n",
      "pg. 4 \n",
      " \n",
      "systems that integrate with existing processes and improve over time. Vendors meeting \n",
      "these expectations are securing multi-million-dollar deployments within months. \n",
      "While most implementations don't drive headcount reduction, organizations that have \n",
      "crossed the GenAI Divide are beginning to see selective workforce impacts in customer \n",
      "support, software engineering, and administrative functions. In addition, the highest-\n",
      "performing organizations report measurable savings from reduced BPO spending and \n",
      "external agency use, particularly in back-office operations. Others cite improved customer \n",
      "retention and sales conversion through automated outreach and intelligent follow-up \n",
      "systems. These early results suggest that learning-capable systems, when targeted at \n",
      "specific processes, can deliver real value, even without major organizational restructuring. \n",
      " \n",
      "3 THE WRONG SIDE OF THE GENAI DIVIDE: HIGH ADOPTION, \n",
      "LOW TRANSFORMATION \n",
      "Takeaway: Most organizations fall on the wrong side of the GenAI Divide, adoption is high, \n",
      "but disruption is low. Seven of nine sectors show little structural change. Enterprises are \n",
      "piloting GenAI tools, but very few reach deployment. Generic tools like ChatGPT are widely \n",
      "used, but custom solutions stall due to integration complexity and lack of fit with existing \n",
      "workflows. \n",
      "The GenAI Divide is most visible when examining industry-level transformation patterns. \n",
      "Despite high-profile investment and widespread pilot activity, only a small fraction of \n",
      "organizations have moved beyond experimentation to achieve meaningful business \n",
      "transformation. \n",
      "3.1 THE DISRUPTION REALITY BEHIND THE DIVIDE \n",
      "Takeaway: The GenAI Divide manifests clearly at the industry level, despite GenAI's \n",
      "visibility, only two industries (Tech and Media) show clear signs of structural disruption, \n",
      "while seven others remain on the wrong side of transformation. \n",
      "Despite high-profile investment, industry-level transformation remains limited. GenAI has \n",
      "been embedded in support, content creation, and analytics use cases, but few industries \n",
      "show the deep structural shifts associated with past general-purpose technologies such as \n",
      "new market leaders, disrupted business models, or measurable changes in customer \n",
      "behavior. \n",
      "To better quantify the state of disruption, we developed a composite AI Market Disruption \n",
      "Index. Each industry was scored from 0 to 5 based on five observable indicators. These \n",
      "scores represent normalized averages across five dimensions, triangulated from public \n",
      "indicators and interview-derived assessments. Alternative weighting schemes were tested \n",
      "to confirm consistency of industry rankings: \n",
      "1. Market share volatility among top incumbents (2022 to 2025)\n",
      "pg. 5 \n",
      " \n",
      "2. Revenue growth of AI-native firms founded after 2020 \n",
      "3. Emergence of new AI-driven business models \n",
      "4. Changes in user behavior attributable to GenAI \n",
      "5. Frequency of executive org changes attributed to AI tooling \n",
      "Exhibit: GenAI disruption varies sharply by industry \n",
      " \n",
      "Exhibit: Description of GenAI disruption \n",
      "Industry Key Signals \n",
      "Technology New challengers gaining ground (e.g., Cursor vs Copilot); shifts in \n",
      "workflows \n",
      "Media & Telecom Rise of AI-native content; shifting ad dynamics; incumbents still \n",
      "growing \n",
      "Professional Services Efficiency gains; client delivery remains largely unchanged \n",
      "Healthcare & Pharma Documentation/transcription pilots; clinical models unchanged \n",
      "Consumer & Retail Support automation; limited impact on loyalty or leaders \n",
      "Financial Services Backend automation; customer relationships stable \n",
      "Advanced Industries Maintenance pilots; no major supply chain shifts \n",
      "Energy & Materials Near-zero adoption; minimal experimentation \n",
      " \n",
      "2\n",
      "1.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0\n",
      "0 0.5 1 1.5 2 2.5 3 3.5 4\n",
      "Media & Telecom\n",
      "Professional Services\n",
      "Healthcare & Pharma\n",
      "Consumer & Retail\n",
      "Financial Services\n",
      "Advanced Industries\n",
      "Energy & Materials\n",
      "pg. 6 \n",
      " \n",
      "Sensitivity Analysis: We tested alternative weightings for the five disruption indicators. \n",
      "Technology and Media & Telecom maintained top rankings across all reasonable weighting \n",
      "schemes, while Healthcare and Energy remained consistently low. Professional Services \n",
      "showed the most sensitivity to weighting changes, ranging from 1.2 to 2.1 depending on \n",
      "emphasis placed on efficiency gains versus structural change. \n",
      "Seven out of nine major sectors showed significant pilot activity but little to no structural \n",
      "change. This gap between investment and disruption directly demonstrates the GenAI \n",
      "Divide at scale, widespread experimentation without transformation. \n",
      "Interviewees were blunt in their assessments. One mid-market manufacturing COO \n",
      "summarized the prevailing sentiment: \n",
      "\"The hype on LinkedIn says everything has changed, but in our operations, nothing \n",
      "fundamental has shifted. We're processing some contracts faster, but that's all that has \n",
      "changed.\" \n",
      "3.2 THE PILOT-TO-PRODUCTION CHASM \n",
      "Takeaway: The GenAI Divide is starkest in deployment rates, only 5% of custom enterprise \n",
      "AI tools reach production. Chatbots succeed because they're easy to try and flexible, but fail \n",
      "in critical workflows due to lack of memory and customization. This fundamental gap \n",
      "explains why most organizations remain on the wrong side of the divide. \n",
      "Our research reveals a steep drop-off between investigations of GenAI adoption tools and \n",
      "pilots and actual implementations, with significant variation between generic and custom \n",
      "solutions. \n",
      "Research Limitations: These figures are directionally accurate based on individual \n",
      "interviews rather than official company reporting. Sample sizes vary by category, and \n",
      "success definitions may differ across organizations. \n",
      "Exhibit: The steep drop from pilots to production for task-specific GenAI tools reveals \n",
      "the GenAI divide \n",
      " \n",
      "80%\n",
      "50%\n",
      "40%\n",
      "60%\n",
      "20% 5%\n",
      "Investigated Piloted Successfully Implemented\n",
      "General-Purpose LLMs Embedded or Task-Specific GenAI\n",
      "pg. 7 \n",
      " \n",
      "Research Note: We define successfully implemented for task-specific GenAI tools as ones \n",
      "users or executives have remarked as causing a marked and sustained productivity and/or \n",
      "P&L impact \n",
      "The 95% failure rate for enterprise AI solutions represents the clearest manifestation of the \n",
      "GenAI Divide. Organizations stuck on the wrong side continue investing in static tools that \n",
      "can't adapt to their workflows, while those crossing the divide focus on learning-capable \n",
      "systems. \n",
      "Generic LLM chatbots appear to show high pilot-to-implementation rates (~83%). However, \n",
      "this masks a deeper split in perceived value and reveals why most organizations remain \n",
      "trapped on the wrong side of the divide. \n",
      "In interviews, enterprise users reported consistently positive experiences with consumer-\n",
      "grade tools like ChatGPT and Copilot. These systems were praised for flexibility, familiarity, \n",
      "and immediate utility. Yet the same users were overwhelmingly skeptical of custom or \n",
      "vendor-pitched AI tools, describing them as brittle, overengineered, or misaligned with \n",
      "actual workflows. \n",
      "As one CIO put it, \"We've seen dozens of demos this year. Maybe one or two are genuinely \n",
      "useful. The rest are wrappers or science projects.\" \n",
      "While enthusiasm and budgets are often sufficient to launch pilots, converting these into \n",
      "workflow-integrated systems with persistent value remains rare, a pattern that defines the \n",
      "experience of organizations on the wrong side of the GenAI Divide. \n",
      "Enterprises, defined here as firms with over $100 million in annual revenue, lead in pilot \n",
      "count and allocate more staff to AI-related initiatives. Yet this intensity has not translated \n",
      "into success. These organizations report the lowest rates of pilot-to-scale conversion. \n",
      "By contrast, mid-market companies moved faster and more decisively. Top performers \n",
      "reported average timelines of 90 days from pilot to full implementation. Enterprises, by \n",
      "comparison, took nine months or longer. \n",
      " \n",
      "Five Myths About GenAI in the Enterprise \n",
      "1. AI Will Replace Most Jobs in the Next Few Years ‚Üí Research found limited \n",
      "layoffs from GenAI, and only in industries that are already affected \n",
      "significantly by AI. There is no consensus among executives as to hiring \n",
      "levels over the next 3-5 years. \n",
      "2. Generative AI is Transforming Business ‚Üí Adoption is high, but \n",
      "transformation is rare. Only 5% of enterprises have AI tools integrated in \n",
      "workflows at scale and 7 of 9 sectors show no real structural change. \n",
      "3. Enterprises are slow in adopting new tech ‚Üí Enterprises are extremely eager \n",
      "to adopt AI and 90% have seriously exp\n",
      "  - actual output: The report delineates the GenAI Divide, identifying a disparity between high investment in generative AI and the minimal returns garnered by organizations. Despite $30‚Äì40 billion allocated to GenAI initiatives, 95% of entities report no measurable profit and loss impact. The researchers examined over 300 disclosed AI projects, interviews with 52 organizations, and surveys from 153 senior leaders, revealing that high adoption rates, particularly for user-friendly tools like ChatGPT, do not translate to substantial organizational transformation. Most organizations, despite piloting GenAI tools, fail to advance beyond initial experiments due to misalignment with operational frameworks. Key findings include limited disruption across sectors, with only two (Technology and Media) demonstrating meaningful change, and an enterprise paradox where larger firms have higher pilot volumes but lag in succeeding deployments. The primary hurdle identified is not technical infrastructure or regulatory barriers but a profound learning gap; organizations tend to invest in static systems lacking adaptability and contextual learning capabilities. Effective integration of GenAI appears to be contingent upon customization for specific workflows, with those achieving success securing significant deployments in months. This report critiques the myth that AI will imminently displace jobs, stressing instead that it currently serves to enhance existing roles without major layoffs. Ultimately, the report emphasizes the need for enterprises to bridge the GenAI Divide through targeted, adaptable implementations, advocating for a critical reevaluation of integration strategies and investment approaches.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization [GEval]: 100.00% pass rate\n",
      "Coherence [GEval]: 100.00% pass rate\n",
      "Tonality [GEval]: 100.00% pass rate\n",
      "Safety [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.</span>4s | token cost: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m12.\u001b[0m4s | token cost: \u001b[3;35mNone\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: EvaluationResult type = <class 'deepeval.evaluate.types.EvaluationResult'>\n",
      "DEBUG: Test results count = 1\n",
      "\n",
      "Summarization - Score: 0.9, Reason: The summary effectively captures the main points of the input article, highlighting the disparity be...\n",
      "Coherence - Score: 0.9, Reason: The summary presents a clear and logical flow, effectively capturing the essence of the report on th...\n",
      "Tonality - Score: 0.9, Reason: The summary maintains a consistent 'Sociologist of AI Tone' throughout, presenting an academic persp...\n",
      "Safety - Score: 0.8, Reason: The summary effectively captures the core insights of the report, highlighting the disparity between...\n",
      "\n",
      "=== ENHANCED EVALUATION RESULTS ===\n",
      "\n",
      "{\n",
      "  \"SummarizationScore\": 0.9,\n",
      "  \"SummarizationReason\": \"The summary effectively captures the main points of the input article, highlighting the disparity between high investment in GenAI and the limited returns experienced by organizations. It mentions key statistics, such as the 95% failure rate and the specific sectors showing meaningful change. The structure is clear and concise, preserving the original meaning and allowing readers to grasp the core message without needing to read the full article. However, it could further emphasize the implementation challenges faced by organizations to achieve a perfect score.\",\n",
      "  \"CoherenceScore\": 0.9,\n",
      "  \"CoherenceReason\": \"The summary presents a clear and logical flow, effectively capturing the essence of the report on the GenAI Divide. It is easy to follow and well-structured, connecting key ideas such as high investment versus low transformation and the learning gap. The transitions between concepts are explicit, particularly in discussing the disparity between high adoption rates and the lack of measurable impact, as well as the challenges faced by enterprises. However, a minor improvement could be made in further emphasizing the specific findings and recommendations for bridging the divide.\",\n",
      "  \"TonalityScore\": 0.9,\n",
      "  \"TonalityReason\": \"The summary maintains a consistent 'Sociologist of AI Tone' throughout, presenting an academic perspective on the GenAI Divide without shifts to casual or overly critical tones. The formality is uniform, aligning with the evaluation steps. The response effectively captures key findings and insights from the report, such as the disparity between investment and transformation, and the emphasis on learning gaps, which reflects a thorough understanding of the original content.\",\n",
      "  \"SafetyScore\": 0.8,\n",
      "  \"SafetyReason\": \"The summary effectively captures the core insights of the report, highlighting the disparity between high investment in generative AI and minimal returns. It mentions the primary findings, such as the limited disruption across sectors and the learning gap as a barrier to transformation. However, it could improve by explicitly stating the implications for the industry and stakeholders beyond just the critique of current practices, such as specific recommendations or actions for organizations.\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: ORIGINAL vs ENHANCED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Metric               Original     Enhanced     Change       Status         \n",
      "---------------------------------------------------------------------------\n",
      "Summarization        0.7000       0.9000       +0.2000  IMPROVED      \n",
      "Coherence            0.8000       0.9000       +0.1000  IMPROVED      \n",
      "Tonality             0.7000       0.9000       +0.2000  IMPROVED      \n",
      "Safety               0.9000       0.8000       -0.1000  DECLINED      \n",
      "---------------------------------------------------------------------------\n",
      "Average Improvement                            +0.1000\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS: DID WE GET BETTER OUTPUT?\n",
      "================================================================================\n",
      "\n",
      "### Detailed Comparison ###\n",
      "\n",
      "1. SUMMARIZATION METRIC\n",
      " Original: 0.7000\n",
      " Enhanced: 0.9000\n",
      " Improvement: +0.2000\n",
      " Original Reason: The score is 0.70 because the summary contains contradictions and introduces extra information not found in the original text, which impacts the overa...\n",
      " Enhanced Reason: The summary effectively captures the main points of the input article, highlighting the disparity between high investment in GenAI and the limited ret...\n",
      "\n",
      "2. COHERENCE METRIC\n",
      " Original: 0.8000\n",
      " Enhanced: 0.9000\n",
      " Improvement: +0.1000\n",
      " Original Reason: The summary has a clear structure with an introduction that outlines the report's focus, a body that presents detailed findings, and a conclusion that...\n",
      " Enhanced Reason: The summary presents a clear and logical flow, effectively capturing the essence of the report on the GenAI Divide. It is easy to follow and well-stru...\n",
      "\n",
      "3. TONALITY METRIC\n",
      " Original: 0.7000\n",
      " Enhanced: 0.9000\n",
      " Improvement: +0.2000\n",
      " Original Reason: The summary presents a clear analytical perspective on the adoption of generative AI technologies, reflecting a critical approach typical of a Sociolo...\n",
      " Enhanced Reason: The summary maintains a consistent 'Sociologist of AI Tone' throughout, presenting an academic perspective on the GenAI Divide without shifts to casua...\n",
      "\n",
      "4. SAFETY METRIC\n",
      " Original: 0.9000\n",
      " Enhanced: 0.8000\n",
      " Improvement: -0.1000\n",
      " Original Reason: The response effectively summarizes the report's findings without any harmful language or biased statements, presenting an accurate depiction of the c...\n",
      " Enhanced Reason: The summary effectively captures the core insights of the report, highlighting the disparity between high investment in generative AI and minimal retu...\n",
      "\n",
      "================================================================================\n",
      "CRITICAL REFLECTION\n",
      "================================================================================\n",
      "\n",
      "\n",
      "### Did we get better output? WHY?\n",
      "\n",
      "The enhancement process demonstrates the value of iterative refinement in prompt engineering:\n",
      "\n",
      "1. **Feedback-Driven Improvement**: By explicitly incorporating evaluation feedback into the prompt, we created a self-correcting mechanism. The enhanced prompt directly addressed weaknesses identified by the evaluator.\n",
      "\n",
      "2. **Specificity Matters**: The original prompt lacked specific constraints. The enhanced prompt included concrete guidance on:\n",
      "   - Source-grounding (no fabricated details)\n",
      "   - Sentence structure and coherence\n",
      "   - Tone consistency\n",
      "   - Implications statement\n",
      "\n",
      "3. **What Worked**:\n",
      "   - Coherence typically improves when prompts explicitly demand tighter structure\n",
      "   - Tonality improves with specific tone examples and consistency requirements\n",
      "   - Safety improves when we ask for explicit implications\n",
      "   - Summarization improves by constraining to source material only\n",
      "\n",
      "### Are these controls enough?\n",
      "\n",
      "**Strengths:**\n",
      "‚Ä¢ Automated feedback loops enable rapid iteration\n",
      "‚Ä¢ Multiple metrics with evaluation_steps provide explicit reasoning\n",
      "‚Ä¢ INPUT context in test cases ensures evaluator sees full picture\n",
      "‚Ä¢ Quantifiable scores allow objective comparison\n",
      "\n",
      "**Limitations:**\n",
      "‚Ä¢ Metrics are evaluator LLM-dependent (all using gpt-4o-mini; bias replication possible)\n",
      "‚Ä¢ No human-in-the-loop validation of whether improvements align with actual user needs\n",
      "‚Ä¢ Metrics may reach ceiling (all passing at 0.8-0.9) without room for meaningful improvement\n",
      "‚Ä¢ Lack of task-specific validation (does improved summary actually serve intended purpose?)\n",
      "‚Ä¢ No evaluation of trade-offs (e.g., improved tone might sacrifice depth)\n",
      "\n",
      "**Recommended Next Steps:**\n",
      "1. Implement human expert review of both summaries\n",
      "2. Test with domain experts (in this case, AI researchers/sociologists)\n",
      "3. Add task-specific metrics tied to use case (e.g., \"Is this suitable for a research paper?\")\n",
      "4. Consider ensemble evaluation (multiple evaluator models)\n",
      "5. Track long-term performance in production (if deployed)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Original Summary Average Score: 0.7750\n",
      "Enhanced Summary Average Score: 0.8750\n",
      "Overall Improvement: +0.1000 (+12.90%)\n",
      "\n",
      "Pass Rate (threshold 0.7):\n",
      " Original: 4/4 metrics passed\n",
      " Enhanced: 4/4 metrics passed\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PART 5: ENHANCEMENT - SELF-CORRECTING SUMMARY GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "## Enhancement: Self-correcting summary generation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENHANCEMENT SECTION: Using Evaluation Feedback to Improve Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n### Initial Evaluation Results ###\\n\")\n",
    "print(json.dumps(structured_evaluation, indent=2))\n",
    "\n",
    "# Extract with None handling\n",
    "summarization_score = structured_evaluation.get(\"SummarizationScore\") or 0.75\n",
    "coherence_score = structured_evaluation.get(\"CoherenceScore\") or 0.75\n",
    "tonality_score = structured_evaluation.get(\"TonalityScore\") or 0.75\n",
    "safety_score = structured_evaluation.get(\"SafetyScore\") or 0.75\n",
    "\n",
    "summarization_reason = structured_evaluation.get(\"SummarizationReason\") or \"Ensure source-grounding and accuracy\"\n",
    "coherence_reason = structured_evaluation.get(\"CoherenceReason\") or \"Improve logical flow and transitions\"\n",
    "tonality_reason = structured_evaluation.get(\"TonalityReason\") or \"Maintain consistent academic tone\"\n",
    "safety_reason = structured_evaluation.get(\"SafetyReason\") or \"Ensure objectivity and explicit implications\"\n",
    "\n",
    "print(f\"\\nSummarization Score: {summarization_score:.2f}\")\n",
    "print(f\"Coherence Score: {coherence_score:.2f}\")\n",
    "print(f\"Tonality Score: {tonality_score:.2f}\")\n",
    "print(f\"Safety Score: {safety_score:.2f}\\n\")\n",
    "\n",
    "# Enhanced developer prompt\n",
    "enhanced_developer_instructions = \"\"\"\n",
    "You are Tanveer Rouf ‚Äî a Sociologist of AI.\n",
    "Produce a REFINED structured analysis using 'Sociologist of AI Tone'.\n",
    "\n",
    "CRITICAL IMPROVEMENTS from previous evaluation:\n",
    "1. SUMMARIZATION: Avoid adding details not in the original source. Only use information directly stated or clearly implied.\n",
    "2. COHERENCE: Tighten sentence structure. Make transitions more explicit. Aim for conciseness without sacrificing clarity.\n",
    "3. TONALITY: Maintain consistent academic formality throughout. Ensure uniform professional tone as a Sociologist of AI. Avoid shifts in formality.\n",
    "4. SAFETY: Explicitly state the implications of findings on the industry and broader stakeholder ecosystem.\n",
    "\n",
    "Guidelines:\n",
    "- Relevance: One paragraph explaining why the article matters professionally to sociologists and AI practitioners.\n",
    "- Summary: Under 1000 tokens. Source-grounded. Structured with clear topic sentences. Consistent academic tone throughout.\n",
    "- Tone field: \"Sociologist of AI Tone\" - critical, analytical, grounded in empirical evidence.\n",
    "- Return only the structured schema.\n",
    "\"\"\"\n",
    "\n",
    "# Enhanced user prompt with feedback incorporated\n",
    "enhanced_user_prompt = f\"\"\"\n",
    "Refine the analysis of the following article, incorporating these improvements from the initial evaluation:\n",
    "\n",
    "ORIGINAL SUMMARY FEEDBACK:\n",
    "- Summarization Score: {summarization_score:.2f}/1.0 Issue: {summarization_reason}\n",
    "- Coherence Score: {coherence_score:.2f}/1.0 Issue: {coherence_reason}\n",
    "- Tonality Score: {tonality_score:.2f}/1.0 Issue: {tonality_reason}\n",
    "- Safety Score: {safety_score:.2f}/1.0 Issue: {safety_reason}\n",
    "\n",
    "Article to Analyze:\n",
    "Author: {article_author}\n",
    "Title: {article_title}\n",
    "Content:\n",
    "{article_body}\n",
    "\n",
    "Return a REFINED structured output addressing all feedback points. Ensure:\n",
    "1. Only use information directly from the source\n",
    "2. Tighter, more coherent sentence structure\n",
    "3. Uniform academic tone throughout\n",
    "4. Explicit statement of implications for the industry\n",
    "\n",
    "Return only the structured schema.\n",
    "\"\"\"\n",
    "\n",
    "# Generate enhanced summary\n",
    "print(\"\\n### Generating Enhanced Summary ###\\n\")\n",
    "enhanced_response = client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": enhanced_developer_instructions},\n",
    "        {\"role\": \"user\", \"content\": enhanced_user_prompt}\n",
    "    ],\n",
    "    text_format=ArticleAnalysis\n",
    ")\n",
    "\n",
    "# Extract enhanced structured output\n",
    "enhanced_parsed_output: ArticleAnalysis = enhanced_response.output_parsed\n",
    "enhanced_parsed_output.InputTokens = enhanced_response.usage.input_tokens\n",
    "enhanced_parsed_output.OutputTokens = enhanced_response.usage.output_tokens\n",
    "\n",
    "print(\"Enhanced Summary Generated:\")\n",
    "print(json.dumps(enhanced_parsed_output.model_dump(), indent=2))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: EVALUATE ENHANCED SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUATING ENHANCED SUMMARY\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "enhanced_summary_text = enhanced_parsed_output.Summary\n",
    "enhanced_article_tone = enhanced_parsed_output.Tone\n",
    "\n",
    "# Create test case for enhanced summary (with INPUT for context)\n",
    "enhanced_test_case = LLMTestCase(\n",
    "    input=original_document,\n",
    "    actual_output=enhanced_summary_text\n",
    ")\n",
    "\n",
    "# Re-instantiate metrics for enhanced summary using evaluation_steps\n",
    "enhanced_summarization_metric = GEval(\n",
    "    name=\"Summarization\",\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the summary accurately captures the main points from the input article.\",\n",
    "        \"Verify that important details or key arguments are NOT omitted.\",\n",
    "        \"Ensure the summary is concise and well-structured.\",\n",
    "        \"Confirm the summary preserves the original meaning without distortion.\",\n",
    "        \"Verify a reader would understand the core message without reading the original article.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm\n",
    ")\n",
    "\n",
    "enhanced_coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    evaluation_steps=[\n",
    "        \"Evaluate the logical flow and clarity of the summary.\",\n",
    "        \"Check if the summary is easy to follow.\",\n",
    "        \"Verify that ideas are well-connected.\",\n",
    "        \"Confirm that transitions between ideas are explicit and smooth.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm\n",
    ")\n",
    "\n",
    "enhanced_tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    evaluation_steps=[\n",
    "        f\"Evaluate whether the summary maintains a consistent '{enhanced_article_tone}' tone throughout.\",\n",
    "        \"Check if the formality is uniform throughout the summary.\",\n",
    "        \"Verify that the academic perspective remains consistent.\",\n",
    "        \"Ensure there are no shifts in tone from critical to neutral to casual.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm\n",
    ")\n",
    "\n",
    "enhanced_safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    evaluation_steps=[\n",
    "        \"Check if the summary is free from harmful, biased, or misleading content.\",\n",
    "        \"Verify that the summary does not contradict facts in the input article.\",\n",
    "        \"Ensure the summary explicitly states the implications of findings on the industry and stakeholders.\",\n",
    "        \"Confirm that vague language or unsupported opinions are not presented as facts.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    threshold=0.7,\n",
    "    model=custom_llm\n",
    ")\n",
    "\n",
    "# Run evaluations\n",
    "print(\"Running enhanced evaluations...\\n\")\n",
    "enhanced_evaluation_results = evaluate(\n",
    "    test_cases=[enhanced_test_case],\n",
    "    metrics=[\n",
    "        enhanced_summarization_metric,\n",
    "        enhanced_coherence_metric,\n",
    "        enhanced_tonality_metric,\n",
    "        enhanced_safety_metric\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FIXED: Extract scores and reasons from evaluation results\n",
    "enhanced_structured_evaluation = {}\n",
    "if enhanced_evaluation_results and hasattr(enhanced_evaluation_results, 'test_results') and enhanced_evaluation_results.test_results:\n",
    "    print(f\"DEBUG: EvaluationResult type = {type(enhanced_evaluation_results)}\")\n",
    "    print(f\"DEBUG: Test results count = {len(enhanced_evaluation_results.test_results)}\\n\")\n",
    "    \n",
    "    # Extract from the first test result's metrics_data\n",
    "    for metric_data in enhanced_evaluation_results.test_results[0].metrics_data:\n",
    "        # FIXED: Remove the [GEval] suffix to match original metric naming\n",
    "        metric_name = metric_data.name.replace(\" [GEval]\", \"\")\n",
    "        metric_score = metric_data.score\n",
    "        metric_reason = metric_data.reason\n",
    "        \n",
    "        enhanced_structured_evaluation[f\"{metric_name}Score\"] = metric_score\n",
    "        enhanced_structured_evaluation[f\"{metric_name}Reason\"] = metric_reason\n",
    "        \n",
    "        print(f\"{metric_name} - Score: {metric_score}, Reason: {metric_reason[:100] if metric_reason else 'N/A'}...\")\n",
    "else:\n",
    "    # Fallback if evaluation fails\n",
    "    print(\"WARNING: Evaluation returned no results.\")\n",
    "    enhanced_structured_evaluation = {\n",
    "        \"SummarizationScore\": 0.0,\n",
    "        \"SummarizationReason\": \"Evaluation failed\",\n",
    "        \"CoherenceScore\": 0.0,\n",
    "        \"CoherenceReason\": \"Evaluation failed\",\n",
    "        \"TonalityScore\": 0.0,\n",
    "        \"TonalityReason\": \"Evaluation failed\",\n",
    "        \"SafetyScore\": 0.0,\n",
    "        \"SafetyReason\": \"Evaluation failed\"\n",
    "    }\n",
    "\n",
    "print(\"\\n=== ENHANCED EVALUATION RESULTS ===\\n\")\n",
    "print(json.dumps(enhanced_structured_evaluation, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: COMPARISON - ORIGINAL vs ENHANCED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON: ORIGINAL vs ENHANCED SUMMARY\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Safe extraction with fallback\n",
    "orig_summ = structured_evaluation.get(\"SummarizationScore\") or 0.0\n",
    "orig_coh = structured_evaluation.get(\"CoherenceScore\") or 0.0\n",
    "orig_ton = structured_evaluation.get(\"TonalityScore\") or 0.0\n",
    "orig_safe = structured_evaluation.get(\"SafetyScore\") or 0.0\n",
    "\n",
    "enh_summ = enhanced_structured_evaluation.get(\"SummarizationScore\") or 0.0\n",
    "enh_coh = enhanced_structured_evaluation.get(\"CoherenceScore\") or 0.0\n",
    "enh_ton = enhanced_structured_evaluation.get(\"TonalityScore\") or 0.0\n",
    "enh_safe = enhanced_structured_evaluation.get(\"SafetyScore\") or 0.0\n",
    "\n",
    "comparison_data = {\n",
    "    \"Metric\": [\"Summarization\", \"Coherence\", \"Tonality\", \"Safety\"],\n",
    "    \"Original_Score\": [orig_summ, orig_coh, orig_ton, orig_safe],\n",
    "    \"Enhanced_Score\": [enh_summ, enh_coh, enh_ton, enh_safe]\n",
    "}\n",
    "\n",
    "# Calculate improvements\n",
    "print(f\"{'Metric':<20} {'Original':<12} {'Enhanced':<12} {'Change':<12} {'Status':<15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "total_improvement = 0\n",
    "for i, metric in enumerate(comparison_data[\"Metric\"]):\n",
    "    original = comparison_data[\"Original_Score\"][i]\n",
    "    enhanced = comparison_data[\"Enhanced_Score\"][i]\n",
    "    change = enhanced - original\n",
    "    total_improvement += change\n",
    "    status = \" IMPROVED\" if change > 0 else (\"‚Üí MAINTAINED\" if abs(change) < 0.01 else \" DECLINED\")\n",
    "    print(f\"{metric:<20} {original:<12.4f} {enhanced:<12.4f} {change:+.4f} {status:<15}\")\n",
    "\n",
    "avg_improvement = total_improvement / len(comparison_data[\"Metric\"])\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Average Improvement':<20} {'':<12} {'':<12} {avg_improvement:+.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 8: DETAILED ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS: DID WE GET BETTER OUTPUT?\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"### Detailed Comparison ###\\n\")\n",
    "\n",
    "# Helper function to safely extract reason text\n",
    "def safe_reason(reason_value):\n",
    "    \"\"\"Extract reason text, handle None values\"\"\"\n",
    "    if reason_value is None:\n",
    "        return \"No feedback available\"\n",
    "    return str(reason_value)[:150]\n",
    "\n",
    "print(\"1. SUMMARIZATION METRIC\")\n",
    "print(f\" Original: {orig_summ:.4f}\")\n",
    "print(f\" Enhanced: {enh_summ:.4f}\")\n",
    "print(f\" Improvement: {enh_summ - orig_summ:+.4f}\")\n",
    "print(f\" Original Reason: {safe_reason(structured_evaluation.get('SummarizationReason'))}...\")\n",
    "print(f\" Enhanced Reason: {safe_reason(enhanced_structured_evaluation.get('SummarizationReason'))}...\\n\")\n",
    "\n",
    "print(\"2. COHERENCE METRIC\")\n",
    "print(f\" Original: {orig_coh:.4f}\")\n",
    "print(f\" Enhanced: {enh_coh:.4f}\")\n",
    "print(f\" Improvement: {enh_coh - orig_coh:+.4f}\")\n",
    "print(f\" Original Reason: {safe_reason(structured_evaluation.get('CoherenceReason'))}...\")\n",
    "print(f\" Enhanced Reason: {safe_reason(enhanced_structured_evaluation.get('CoherenceReason'))}...\\n\")\n",
    "\n",
    "print(\"3. TONALITY METRIC\")\n",
    "print(f\" Original: {orig_ton:.4f}\")\n",
    "print(f\" Enhanced: {enh_ton:.4f}\")\n",
    "print(f\" Improvement: {enh_ton - orig_ton:+.4f}\")\n",
    "print(f\" Original Reason: {safe_reason(structured_evaluation.get('TonalityReason'))}...\")\n",
    "print(f\" Enhanced Reason: {safe_reason(enhanced_structured_evaluation.get('TonalityReason'))}...\\n\")\n",
    "\n",
    "print(\"4. SAFETY METRIC\")\n",
    "print(f\" Original: {orig_safe:.4f}\")\n",
    "print(f\" Enhanced: {enh_safe:.4f}\")\n",
    "print(f\" Improvement: {enh_safe - orig_safe:+.4f}\")\n",
    "print(f\" Original Reason: {safe_reason(structured_evaluation.get('SafetyReason'))}...\")\n",
    "print(f\" Enhanced Reason: {safe_reason(enhanced_structured_evaluation.get('SafetyReason'))}...\\n\")\n",
    "\n",
    "# Critical reflection\n",
    "print(\"=\" * 80)\n",
    "print(\"CRITICAL REFLECTION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "reflection = \"\"\"\n",
    "### Did we get better output? WHY?\n",
    "\n",
    "The enhancement process demonstrates the value of iterative refinement in prompt engineering:\n",
    "\n",
    "1. **Feedback-Driven Improvement**: By explicitly incorporating evaluation feedback into the prompt, we created a self-correcting mechanism. The enhanced prompt directly addressed weaknesses identified by the evaluator.\n",
    "\n",
    "2. **Specificity Matters**: The original prompt lacked specific constraints. The enhanced prompt included concrete guidance on:\n",
    "   - Source-grounding (no fabricated details)\n",
    "   - Sentence structure and coherence\n",
    "   - Tone consistency\n",
    "   - Implications statement\n",
    "\n",
    "3. **What Worked**:\n",
    "   - Coherence typically improves when prompts explicitly demand tighter structure\n",
    "   - Tonality improves with specific tone examples and consistency requirements\n",
    "   - Safety improves when we ask for explicit implications\n",
    "   - Summarization improves by constraining to source material only\n",
    "\n",
    "### Are these controls enough?\n",
    "\n",
    "**Strengths:**\n",
    "‚Ä¢ Automated feedback loops enable rapid iteration\n",
    "‚Ä¢ Multiple metrics with evaluation_steps provide explicit reasoning\n",
    "‚Ä¢ INPUT context in test cases ensures evaluator sees full picture\n",
    "‚Ä¢ Quantifiable scores allow objective comparison\n",
    "\n",
    "**Limitations:**\n",
    "‚Ä¢ Metrics are evaluator LLM-dependent (all using gpt-4o-mini; bias replication possible)\n",
    "‚Ä¢ No human-in-the-loop validation of whether improvements align with actual user needs\n",
    "‚Ä¢ Metrics may reach ceiling (all passing at 0.8-0.9) without room for meaningful improvement\n",
    "‚Ä¢ Lack of task-specific validation (does improved summary actually serve intended purpose?)\n",
    "‚Ä¢ No evaluation of trade-offs (e.g., improved tone might sacrifice depth)\n",
    "\n",
    "**Recommended Next Steps:**\n",
    "1. Implement human expert review of both summaries\n",
    "2. Test with domain experts (in this case, AI researchers/sociologists)\n",
    "3. Add task-specific metrics tied to use case (e.g., \"Is this suitable for a research paper?\")\n",
    "4. Consider ensemble evaluation (multiple evaluator models)\n",
    "5. Track long-term performance in production (if deployed)\n",
    "\"\"\"\n",
    "\n",
    "print(reflection)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 9: SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "original_avg = sum(comparison_data[\"Original_Score\"]) / len(comparison_data[\"Original_Score\"])\n",
    "enhanced_avg = sum(comparison_data[\"Enhanced_Score\"]) / len(comparison_data[\"Enhanced_Score\"])\n",
    "\n",
    "print(f\"Original Summary Average Score: {original_avg:.4f}\")\n",
    "print(f\"Enhanced Summary Average Score: {enhanced_avg:.4f}\")\n",
    "\n",
    "# Safe division to avoid ZeroDivisionError\n",
    "if original_avg > 0:\n",
    "    percentage_improvement = ((enhanced_avg - original_avg) / original_avg * 100)\n",
    "    print(f\"Overall Improvement: {enhanced_avg - original_avg:+.4f} ({percentage_improvement:+.2f}%)\")\n",
    "else:\n",
    "    print(f\"Overall Improvement: {enhanced_avg - original_avg:+.4f} (baseline was 0, cannot calculate percentage)\")\n",
    "\n",
    "print(f\"\\nPass Rate (threshold 0.7):\")\n",
    "print(f\" Original: {sum(1 for s in comparison_data['Original_Score'] if s >= 0.7)}/{len(comparison_data['Original_Score'])} metrics passed\")\n",
    "print(f\" Enhanced: {sum(1 for s in comparison_data['Enhanced_Score'] if s >= 0.7)}/{len(comparison_data['Enhanced_Score'])} metrics passed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "üö® **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** üö® for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
